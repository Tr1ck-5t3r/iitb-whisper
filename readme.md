# OpenAI Whisper Evaluation

## Introduction

OpenAI Whisper is an innovative tool designed to transcribe and translate audio recordings into multiple languages. The objective of this project was to implement OpenAI Whisper on the Kathbath dataset and evaluate the model's performance using Word Error Rate (WER).

## About

This repository contains implementations of OpenAI Whisper on two datasets: the Kathbath dataset and the IIT-B dataset. The Kathbath dataset was utilized for testing purposes, along with the dataset provided by IIT-B. The implementation was carried out in separate Jupyter notebooks for each dataset, along with the corresponding datasets and the results of transcriptions.

### Kathbath Dataset

- **Code**: `kathbath-whisper.ipynb`
- **Results**: `results-kathbath-whisper.csv`

### IIT Dataset

- **Code**: `iit-assignment-whisper.ipynb`
- **Results**: `results-iit-assignment-whisper.csv`

## Results

The performance of the model was evaluated based on the Word Error Rate (WER) metric.

- **Kathbath Dataset**: The model achieved a WER of 40.75%.
- **IIT-B Dataset**: The model achieved a WER of 69.02%.

## Conclusion

In conclusion, the model demonstrated promising performance in transcribing the Kathbath dataset with a WER of 40.75%. The implementation of OpenAI Whisper on the Kathbath dataset was successful, and the model's performance was evaluated using WER. I am grateful for the opportunity to work on this project and am keen to contribute to your team. Thank you for considering my application and for your time.
